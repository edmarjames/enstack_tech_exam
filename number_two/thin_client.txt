Question 1: Assuming that the device is sending continuously at 16000Hz for the X,Y, and Z acceleration measurements, what would your strategy be in handling and processing the data? How would you design the server infrastructure? Please enumerate the steps, software, algorithms, and services that you would use to ensure that the servers can handle the incoming data from our users. Diagrams can be really helpful for this.


1. Understanding the Data Load
- Each device sends acceleration data for X, Y, and Z axes at 16,000 Hz.
- If each measurement consists of three 32-bit (4-byte) float values, the raw data per second per device is:

  16,000 * 3 * 4 = 192,000 bytes = 192 KB per second per device

- If we have 10,000 devices, the total incoming data per second is:

  192 * 10,000 = 1.92 GB/sec


2. High-Level Architecture
We need a scalable and resilient pipeline to handle the data. The main components of our system:

1. Edge Processing (Preprocessing at the Client)
   - Downsampling: If ultra-high resolution isn’t needed, reduce the sampling rate (e.g., average over 10ms windows).
   - Compression: Use a lightweight protocol like Google’s Protocol Buffers (protobuf) instead of JSON.
   - Batching: Instead of sending each sample separately, send data in chunks (e.g., every 100ms → reduces API calls by 100x).

2. Ingestion Layer (Handling High Throughput Data)
   - Load Balancer: AWS NLB for routing traffic.
   - Streaming Message Queue: Apache Kafka to handle the high ingestion rate.

3. Real-Time Processing (Optional)
   - Stream Processing Engine: Apache Flink for real-time anomaly detection, filtering, or feature extraction.

4. Storage Layer
   - Hot Storage (Short-term, Fast Retrieval): Redis for real-time dashboards.
   - Cold Storage (Long-term, Analytics): AWS S3.
   - Database (Indexed Querying): PostgreSQL (TimescaleDB extension) for time-series analysis.

5. Processing & Machine Learning
   - Batch Processing: Apache Spark for aggregations.
   - ML Pipelines: Scikit-Learn for pattern recognition and anomaly detection.
   - Dashboards & Reporting: Grafana for real-time visualization.


3. Step-by-Step Data Flow

1️. Thin Client (Sensor)
   - Reads accelerometer data (X, Y, Z at 16,000Hz).
   - Applies downsampling (optional, to reduce noise).
   - Batches data (e.g., send data every 100ms instead of per sample).
   - Compresses data using Protocol Buffers (protobuf).
   - Sends data via MQTT to the ingestion layer.

2. Ingestion Layer
   - AWS NLB (Network Load Balancer) directs data traffic efficiently.
   - Data is ingested into Apache Kafka (for durable, replayable message queuing).

3. Real-Time Processing
   - Apache Flink processes streaming data:
      - Detects anomalies (e.g., sudden acceleration spikes).
      - Filters out noise (e.g., sensor glitches).
      - Extracts features (e.g., rolling averages, peaks).
      - Redis stores latest processed values for real-time dashboards.

4. Storage & Batch Processing
   - TimescaleDB (PostgreSQL extension) stores structured time-series sensor data for querying.
   - AWS S3 stores raw sensor data for long-term analytics and ML training.
   - Apache Spark runs batch jobs on AWS S3 data for trend analysis and historical insights.

5. Analytics & Machine Learning
   - Grafana visualizes live sensor data from Redis & TimescaleDB.
   - Scikit-Learn detects unusual patterns/anomalies in batch data.
   - Processed ML insights are stored in TimescaleDB or fed back into Flink for real-time adjustments.


4. Software & Services
Component | Technology Choices
* Protocol - MQTT
* Compression - Protobuf
* Load Balancer - AWS NLB
* Message Queue - Apache Kafka
* Real-Time Processing - Apache Flink
* Hot Storage (cache) - Redis
* Database (Time-series) - TimescaleDB (PostgreSQL)
* Cold Storage (long-term) - AWS S3
* Batch processing - Apache spark
* Visualization - Grafana
* ML & Analytics - Scikit-Learn



Question 2: If the sensors were upgraded to modern mobile devices, how would you change your architecture from A?

If the sensors were upgraded to modern mobile devices, several architectural changes would be beneficial to leverage the increased processing power, connectivity, and sensor capabilities.
Below are the key modifications:


Key Architectural Changes
1. Edge Processing (More Local Processing on Mobile Devices)
- More On-Device Computation:
  - Mobile devices have more CPU/GPU power, allowing for on-device feature extraction (e.g., computing statistical summaries, detecting anomalies before sending data).
  - New Addition: TensorFlow Lite for on-device ML inference to reduce unnecessary data transmission.

- Less Frequent Data Transmission:
  - Instead of sending raw data at 16,000Hz, the device can pre-process and send only relevant events (e.g., detected movements, thresholds exceeded).

- Adaptive Batching & Compression:
  - Instead of fixed batching, mobile devices can dynamically adjust batch sizes based on network conditions to save bandwidth.


2. Ingestion Layer (Smarter Data Routing)
- Protocol Change:
  - Switch from MQTT to WebSockets or gRPC
    - Since mobile devices support stable TCP/WebSockets, we can use gRPC for faster, binary-encoded communication instead of MQTT.
    - Still keep MQTT for unstable network scenarios (e.g., low connectivity regions).

- Edge-to-Cloud Synchronization (Optional)
  - New Addition: If mobile devices temporarily go offline, they should buffer data and sync it to the cloud when reconnected.


3. Real-Time Processing & Storage (More Decentralized)
- Lighter Load on Cloud Processing:
  - Since more feature extraction and filtering is done on-device, Flink needs to process less raw data and focus on aggregations.

- Edge Storage (Optional for Mobile-First Apps)
  - New Addition: SQLite or local storage (for temporary caching before upload).

- Data Storage Adjustments:
  - Redis (for live dashboards) remains unchanged.
  - TimescaleDB/PostgreSQL (for structured event storage) remains unchanged.
  - AWS S3 (for raw historical logs) remains unchanged.


4. Machine Learning Adjustments
- More On-Device Inference → Less Cloud ML Load
  - Instead of running all ML models in the cloud, some models (like motion pattern detection) can run on-device using TensorFlow Lite.

- Cloud ML Still Needed for Model Updates
  - Cloud ML models Scikit-Learn can be used for retraining models and updating on-device inference models periodically.